{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dofMeExYzVLJ"
      },
      "source": [
        "# Практическое задание\n",
        "\n",
        "## Данные о студенте\n",
        "\n",
        "1. **ФИО**: Ковалев Виктор Васильевич\n",
        "2. **Факультет**: МехМат\n",
        "3. **Курс**: 1, магистратура\n",
        "4. **Группа**: М1\n",
        "\n",
        "## Замечания\n",
        "\n",
        "* Заполненный ноутбук необходимо сдать боту\n",
        "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
        "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
        "* Ничего, крому Numpy, нельзя использовать для реализации\n",
        "* **Keras** используется только для тестирования Вашей реализации\n",
        "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
        "* Возможно использование дополнительных (приватных) тестов\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Примечание: задание делалось в google colab, поэтому немного были изменены импорты  из keras. Поэтому в jupiter notebook может работать не корректно**"
      ],
      "metadata": {
        "id": "zoL6u2XhRhVY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mED9cQaVzVLK"
      },
      "source": [
        "## Реализация собственного нейросетевого пакета для запуска и обучения нейронных сетей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwH-wYH_zVLL"
      },
      "source": [
        "Задание состоит из трёх частей:\n",
        "1. Реализация прямого вывода нейронной сети (5 баллов)\n",
        "2. Реализация градиентов по входу и распространения градиента по сети (5 баллов)\n",
        "3. Реализация градиентов по параметрам и метода обратного распространения ошибки с обновлением парметров сети (10 баллов)\n",
        "\n",
        "Дополнительные баллы можно получить при реализации обучения сети со свёрточными слоями (10 баллов), с транспонированной свёрткой (10 баллов), дополнительного оптимизатора (5 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b22M8_UbzVLM"
      },
      "source": [
        "###  1. Реализация вывода собственной нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdaxQDT8zVLM"
      },
      "source": [
        "1.1 Внимательно ознакомьтесь с интерфейсом слоя. Любой слой должен содержать как минимум три метода:\n",
        "- конструктор\n",
        "- прямой вывод\n",
        "- обратный вывод, производные по входу и по параметрам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6V6YSYu_zVLM"
      },
      "outputs": [],
      "source": [
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.name = 'Layer'\n",
        "    def forward(self, input_data):\n",
        "        pass\n",
        "    def backward(self, input_data):\n",
        "        return [self.grad_x(input_data), self.grad_param(input_data)]\n",
        "\n",
        "    def grad_x(self, input_data):\n",
        "        pass\n",
        "    def grad_param(self, input_data):\n",
        "        return []\n",
        "\n",
        "    def update_param(self, grads, learning_rate):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvmaAeVezVLN"
      },
      "source": [
        "1.2 Ниже предствален интерфейс класса  Network. Обратите внимание на реализацию метода predict, который последовательно обрабатывает входные данные слой за слоем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vGFwMfCUzVLN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Network(object):\n",
        "    def __init__(self, layers, loss=None):\n",
        "        self.name = 'Network'\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        return self.predict(input_data)\n",
        "\n",
        "    def grad_x(self, input_data, labels):\n",
        "        inputs=input_data\n",
        "        my_list=[]\n",
        "        for layer in self.layers:\n",
        "            my_list.append(inputs)\n",
        "            inputs=layer.forward(inputs)\n",
        "        out=self.loss.grad_x(inputs,labels)\n",
        "        inputs_list=my_list[::-1]\n",
        "        for i,layer in enumerate(self.layers[::-1]):\n",
        "            if layer.name == 'Softmax':\n",
        "                output_softmax=layer.forward(inputs_list[i])\n",
        "                out= output_softmax-labels\n",
        "            elif layer.name == 'Dense':\n",
        "                dense_list=[]\n",
        "                for data in out:\n",
        "                    # print(data.shape,layer.W.T.shape)\n",
        "                    dense_list.append(data @ layer.W.T)\n",
        "                out=np.array(dense_list)\n",
        "                # out=out.sum(axis=0)\n",
        "            elif layer.name == 'ReLU':\n",
        "                relu_list=[]\n",
        "                for j,data in enumerate(out):\n",
        "                    relu_list.append(data  @ layer.grad_x(inputs_list[i])[j].T)\n",
        "                out=np.array(relu_list)\n",
        "                # out=out.sum(axis=0)\n",
        "            else:\n",
        "                pass\n",
        "        return out.sum(axis=0)\n",
        "    def grad_param(self, input_data, labels):\n",
        "        inputs=input_data\n",
        "        grad_list=[]\n",
        "        my_list=[]\n",
        "        for layer in self.layers:\n",
        "            my_list.append(inputs)\n",
        "            inputs=layer.forward(inputs)\n",
        "        out=self.loss.grad_x(inputs,labels)\n",
        "        inputs_list=my_list[::-1]\n",
        "        for i,layer in enumerate(self.layers[::-1]):\n",
        "            if layer.name == 'Softmax':\n",
        "                output_softmax=layer.forward(inputs_list[i])\n",
        "                out= output_softmax-labels\n",
        "                grad_list.append(0)\n",
        "                # print(out.shape)\n",
        "            elif layer.name == 'Dense':\n",
        "                w_list=[]\n",
        "                for j,data in enumerate(out):\n",
        "                    w_list.append(data @ layer.grad_W(inputs_list[i])[j])\n",
        "                grad_list.append([np.array(w_list),out])\n",
        "                # out=out @ layer.W.T\n",
        "                dense_list=[]\n",
        "                for data in out:\n",
        "                    # print(data.shape,layer.W.T.shape)\n",
        "                    dense_list.append(data @ layer.W.T)\n",
        "                out=np.array(dense_list)\n",
        "                # print(out.shape)\n",
        "            elif layer.name == 'ReLU':\n",
        "                grad_list.append(0)\n",
        "                relu_list=[]\n",
        "                for j,data in enumerate(out):\n",
        "                    # print(data,layer.grad_x(inputs_list[i])[j])\n",
        "                    relu_list.append(data  @ layer.grad_x(inputs_list[i])[j])\n",
        "                out=np.array(relu_list)\n",
        "                # print(out.shape)\n",
        "            else:\n",
        "                pass\n",
        "        return grad_list\n",
        "    def update(self, grad_list, learning_rate):\n",
        "        for i,layer in enumerate(self.layers[::-1]):\n",
        "            if layer.name=='Dense':\n",
        "                grad_w,grad_b=grad_list[i]\n",
        "                layer.update_W(grad_w ,learning_rate)\n",
        "                layer.update_b(grad_b ,learning_rate)\n",
        "    def predict(self, input_data):\n",
        "        current_input = input_data\n",
        "        for layer in self.layers:\n",
        "            current_input = layer.forward(current_input)\n",
        "        return current_input\n",
        "\n",
        "    def calculate_loss(self, input_data, labels):\n",
        "        return self.loss.forward(self.predict(input_data), labels)\n",
        "\n",
        "    def train_step(self, input_data, labels, learning_rate=0.001):\n",
        "        grad_list = self.grad_param(input_data, labels)\n",
        "        self.update(grad_list, learning_rate)\n",
        "\n",
        "    def fit(self, trainX, trainY, validation_split=0.25,\n",
        "            batch_size=1, nb_epoch=1, learning_rate=0.01):\n",
        "\n",
        "        train_x, val_x, train_y, val_y = train_test_split(trainX, trainY,\n",
        "                                                          test_size=validation_split,\n",
        "                                                          random_state=42)\n",
        "        for epoch in range(nb_epoch):\n",
        "            #train one epoch\n",
        "            for i in tqdm(range(int(len(train_x)/batch_size))):\n",
        "                batch_x = train_x[i*batch_size: (i+1)*batch_size]\n",
        "                batch_y = train_y[i*batch_size: (i+1)*batch_size]\n",
        "                self.train_step(batch_x, batch_y, learning_rate)\n",
        "            #validate\n",
        "            val_accuracy = self.evaluate(val_x, val_y)\n",
        "            print('%d epoch: val %.2f' %(epoch+1, val_accuracy))\n",
        "\n",
        "    def evaluate(self, testX, testY):\n",
        "        y_pred = np.argmax(self.predict(testX), axis=1)\n",
        "        y_true = np.argmax(testY, axis=1)\n",
        "        val_accuracy = np.sum((y_pred == y_true))/(len(y_true))\n",
        "        return val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTKWI7xGzVLN"
      },
      "source": [
        "#### 1.1 Необходимо реализовать метод forward для вычисления следующих слоёв:\n",
        "\n",
        "- DenseLayer\n",
        "- ReLU\n",
        "- Softmax\n",
        "- FlattenLayer\n",
        "- MaxPooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8C7y2fUQzVLN"
      },
      "outputs": [],
      "source": [
        "#импорты\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iN_izj4KzVLN"
      },
      "outputs": [],
      "source": [
        "class DenseLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
        "        self.name = 'Dense'\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        if W_init is None:\n",
        "            # self.W = np.random.randn(input_dim, output_dim)\n",
        "            self.W =np.eye(input_dim, output_dim)\n",
        "        else:\n",
        "            self.W = W_init\n",
        "        if b_init is None:\n",
        "            self.b = np.zeros(output_dim)\n",
        "        else:\n",
        "            self.b = b_init\n",
        "    def forward(self, input_data):\n",
        "        out=np.empty((input_data.shape[0],self.output_dim))\n",
        "        # print(self.W.shape,input_data.shape)\n",
        "        for i,mat in enumerate(input_data):\n",
        "            my_mat= mat @ self.W + self.b\n",
        "            # print(self.W.shape)\n",
        "            out[i]=my_mat\n",
        "        # print(np.mean(out))\n",
        "        return out\n",
        "    def grad_x(self, input_data):\n",
        "        n=input_data.shape[0]\n",
        "        my_shape=(n,*self.W.T.shape)\n",
        "        out=np.empty(my_shape)\n",
        "        for i in range(n):\n",
        "            out[i]=self.W.T\n",
        "        return out\n",
        "    def grad_b(self, input_data):\n",
        "        my_list=[]\n",
        "        for i in range(input_data.shape[0]):\n",
        "            my_list.append(np.eye(self.b.shape[-1],self.b.shape[-1]))\n",
        "        return np.array(my_list)\n",
        "\n",
        "    def grad_W(self, input_data):\n",
        "        my_list=[]\n",
        "        n=self.output_dim\n",
        "        for x in input_data:\n",
        "            my_matrix=[]\n",
        "            for i in range(n):\n",
        "                my_vektor=np.zeros((self.input_dim,n)).T\n",
        "                # print(my_vektor.shape)\n",
        "                my_vektor[i]=x\n",
        "                my_matrix.append(my_vektor.T.flatten())\n",
        "            my_list.append(my_matrix)\n",
        "        return np.array(my_list)\n",
        "\n",
        "\n",
        "    def update_W(self, grad, learning_rate):\n",
        "        self.W -= learning_rate * np.mean(grad, axis=0).reshape(self.W.shape)\n",
        "\n",
        "    def update_b(self, grad,  learning_rate):\n",
        "        self.b -= learning_rate * np.mean(grad, axis=0).reshape(self.b.shape)\n",
        "\n",
        "    def update_param(self, params_grad, learning_rate):\n",
        "        self.update_W(params_grad[0], learning_rate)\n",
        "        self.update_b(params_grad[1], learning_rate)\n",
        "\n",
        "    def grad_param(self, input_data):\n",
        "        return [self.grad_W(input_data), self.grad_b(input_data)]\n",
        "\n",
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        self.name = 'ReLU'\n",
        "    def forward(self, input_data):\n",
        "        return np.array([[max(0,x) for x in data]for data in input_data])\n",
        "    def grad_x(self, input_data):\n",
        "        my_shape=(input_data.shape[0],input_data.shape[1],input_data.shape[1])\n",
        "        out=np.zeros(my_shape)\n",
        "        my_arr=self.forward(input_data)\n",
        "        for i in range(my_shape[0]):\n",
        "            for j in range(my_shape[1]):\n",
        "                if my_arr[i,j]>0:\n",
        "                    out[i,j,j]=1\n",
        "        return out\n",
        "\n",
        "class Softmax(Layer):\n",
        "    def __init__(self):\n",
        "        self.name = 'Softmax'\n",
        "    def forward(self, input_data):\n",
        "        out=np.empty(input_data.shape)\n",
        "        for i,data in enumerate(input_data):\n",
        "            exp_values = np.exp(data - np.max(data))\n",
        "            out[i]=exp_values/sum(exp_values)\n",
        "        return out\n",
        "    def grad_x(self, input_data):\n",
        "        my_shape=(input_data.shape[0],input_data.shape[1],input_data.shape[1])\n",
        "        out=np.empty(my_shape)\n",
        "        soft_arr=self.forward(input_data)\n",
        "        for i in range(my_shape[0]):\n",
        "            for j in range(my_shape[1]):\n",
        "                for k in range(j,my_shape[2]):\n",
        "                  if j==k:\n",
        "                      out[i,j,k]=soft_arr[i][j]*(1-soft_arr[i][j])\n",
        "                  else:\n",
        "                      out[i,j,k]=-soft_arr[i][j]*soft_arr[i][k]\n",
        "                      out[i,k,j]=-soft_arr[i][j]*soft_arr[i][k]\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FlattenLayer(Layer):\n",
        "    def __init__(self):\n",
        "        self.name = 'Flatten'\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        # print(input_data.shape)\n",
        "        num,c,h,w=input_data.shape\n",
        "        out=np.empty((num,c*h*w))\n",
        "        for i,matrix in enumerate(input_data):\n",
        "            out[i]=matrix.flatten()\n",
        "\n",
        "        return out\n",
        "    def grad_x(self):\n",
        "        pass\n",
        "class MaxPooling(Layer):\n",
        "    def __init__(self,kernel_size=2):\n",
        "        self.name = 'MaxPool'\n",
        "        self.ker_size=kernel_size\n",
        "    def forward(self,input_data):\n",
        "        batch,chenal,h,w=input_data.shape\n",
        "        x_stop=w\n",
        "        y_stop=h\n",
        "        stride=self.ker_size\n",
        "        out=np.empty((batch,chenal,h//self.ker_size,w//self.ker_size))\n",
        "        for n_bat in range(batch):\n",
        "            for n_chenal in range(chenal):\n",
        "                for i in range(0,y_stop,self.ker_size):\n",
        "                    for j in range(0,x_stop,self.ker_size):\n",
        "                        my_max=np.max(input_data[n_bat,n_chenal,i:i+self.ker_size,j:j+self.ker_size])\n",
        "                        out[n_bat,n_chenal,i//self.ker_size,j//self.ker_size]=my_max\n",
        "        return out\n",
        "    def grad_x(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WckE62yyzVLO"
      },
      "source": [
        "#### 1.2 Реализуйте теперь свёрточный слой и транспонированную свёртку  (опционально)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fG9hMw8ozVLO"
      },
      "outputs": [],
      "source": [
        "class Conv2DLayer(Layer):\n",
        "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3,\n",
        "                 padding='same', stride=1, K_init=None, b_init=None):\n",
        "        # padding: 'same' или 'valid'\n",
        "        # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
        "        # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
        "        # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
        "        self.name = 'Conv2D'\n",
        "        self.kernel_size = kernel_size\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.kernel = K_init\n",
        "        self.bias = b_init\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "    def forward(self, input_data):\n",
        "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
        "        # Нужно заполнить Numpy-тензор out\n",
        "        #свертка скопирова из предыдущего дз\n",
        "        if self.kernel is None:\n",
        "            ker=np.eye((self.kernel_size,self.kernel_size))\n",
        "        else:\n",
        "            ker=self.kernel\n",
        "        if self.padding=='valid':\n",
        "            _,_,h,w=input_data.shape\n",
        "            start_y=self.kernel_size//2\n",
        "            stop_y=h-self.kernel_size//2\n",
        "            start_x=self.kernel_size//2\n",
        "            stop_x=w-self.kernel_size//2\n",
        "            my_list=[]\n",
        "            def conv(num,c,i,j,my_kernel=self.kernel,my_bias=self.bias,\n",
        "                     my_tensor=input_data,ker_size=3,input_chanels=2):\n",
        "                Yijk=0\n",
        "                for m in range(input_chanels):\n",
        "                    for kh in range(ker_size):\n",
        "                        for kw in range(ker_size):\n",
        "                            Yijk+=my_kernel[kh][kw][m][c]*my_tensor[num][i-2+kh][j-2+kw][m]\n",
        "                Yijk+=my_bias[c]\n",
        "                return Yijk\n",
        "            my_list=[]\n",
        "            for num in range(self.output_channels):\n",
        "                my_list_i=[]\n",
        "                for i in range(start_y,stop_y,self.stride):\n",
        "                    my_list_j=[]\n",
        "                    for j in range(start_x,stop_x,self.stride):\n",
        "                        my_list_c=[]\n",
        "                        for c in range(self.output_channels):\n",
        "                            Ynumijk=conv(num,c,i,j,my_kernel=self.kernel,my_bias=self.bias,\n",
        "                                         my_tensor=input_data,ker_size=self.kernel_size,input_channels=self.input_channels)\n",
        "                            my_list_c.append(Ynumijk)\n",
        "                        my_list_j.append(my_list_c)\n",
        "                    my_list_i.append(my_list_j)\n",
        "                my_list.append(my_list_i)\n",
        "            my_tensor_final=np.array(my_list)\n",
        "            return my_tensor_final\n",
        "        else:\n",
        "            _,_,h,w=input_data.shape\n",
        "        out = np.empty([])\n",
        "        return out\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        pass\n",
        "    def grad_x(self):\n",
        "        pass\n",
        "    def grad_kernel(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dwLKPpo_zVLO"
      },
      "outputs": [],
      "source": [
        "class Conv2DTrLayer(Layer):\n",
        "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3,\n",
        "                 padding=0, stride=1, K_init=None, b_init=None):\n",
        "        # padding: число (сколько отрезать от модифицированной входной карты)\n",
        "        # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
        "        # stride - одно число (коэффициент расширения)\n",
        "        # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
        "        self.name = 'Conv2DTr'\n",
        "        self.kernel_size = kernel_size\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.kernel = K_init\n",
        "        self.bias = b_init\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "    def forward(self, input_data):\n",
        "        # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
        "        # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
        "        # Нужно заполнить Numpy-тензор out\n",
        "        out = np.empty([])\n",
        "        return out\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        pass\n",
        "    def grad_x(self):\n",
        "        pass\n",
        "    def grad_kernel(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGL6spEGzVLO"
      },
      "source": [
        "#### 1.4 Теперь настало время теста.\n",
        "#### Если вы всё сделали правильно, то запустив следующие ячейки у вас должна появиться надпись: Test PASSED\n",
        "\n",
        "Переходить к дальнейшим заданиям не имеем никакого смысла, пока вы не добьётесь прохождение теста\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN5a7_ZPotCj",
        "outputId": "0df7f8b4-cfc4-4286-ca57-e629e5269a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzr5vHBdzVLP"
      },
      "source": [
        "#### Чтение данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxiCwAIkzVLP",
        "outputId": "5bca910b-32b0-442d-8365-a59999f54c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 1, 28, 28) (60000, 10) (10000, 1, 28, 28) (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(123)  # for reproducibility\n",
        "# from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "\n",
        "Y_train = keras.utils.to_categorical(y_train, 10)\n",
        "Y_test = keras.utils.to_categorical(y_test, 10)\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1c45seAzVLQ"
      },
      "source": [
        "#### Подготовка моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IuRk5rvzVLQ",
        "outputId": "8301dbc8-133a-4491-ac96-b9da2f0bd3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8.0\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D\n",
        "\n",
        "print(keras.__version__)\n",
        "\n",
        "def get_keras_model():\n",
        "    input_image = Input(shape=(1, 28, 28))\n",
        "    pool1 = MaxPooling2D(pool_size=(2,2), data_format='channels_first')(input_image)\n",
        "    flatten = Flatten()(pool1)\n",
        "    dense1 = Dense(10, activation='softmax')(flatten)\n",
        "    model = Model(inputs=input_image, outputs=dense1)\n",
        "\n",
        "    from keras.optimizers import Adam, SGD\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=sgd,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, Y_train, validation_split=0.25,\n",
        "                        batch_size=32, epochs=2, verbose=1)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SeXIZ_UUzVLQ"
      },
      "outputs": [],
      "source": [
        "def get_our_model(keras_model):\n",
        "    maxpool = MaxPooling()\n",
        "    flatten = FlattenLayer()\n",
        "    input_image = Input(shape=(1, 28, 28))\n",
        "    model = Sequential([\n",
        "    MaxPooling2D(pool_size=(2,2), data_format='channels_first', input_shape=(1, 28, 28))])\n",
        "    dense = DenseLayer(196, 10, W_init=keras_model.get_weights()[0],\n",
        "                       b_init=keras_model.get_weights()[1])\n",
        "    softmax = Softmax()\n",
        "    net = Network([maxpool,flatten, dense, softmax])\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6eAd3DJzVLR",
        "outputId": "bc26493d-3155-4d13-813c-7630cc76665f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7731 - loss: 0.8455 - val_accuracy: 0.8927 - val_loss: 0.3807\n",
            "Epoch 2/2\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8883 - loss: 0.3888 - val_accuracy: 0.9019 - val_loss: 0.3427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/pooling/base_pooling.py:23: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(name=name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "keras_model = get_keras_model()\n",
        "our_model = get_our_model(keras_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdwAwOqszVLR",
        "outputId": "0a3085dc-167c-46db-8db6-de3ffb5aa4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "keras_prediction = keras_model.predict(X_test)\n",
        "our_model_prediction = our_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icarf4GHzVLR",
        "outputId": "43f89949-55ff-4ec5-e3d0-73c668d7ccb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if np.sum(np.abs(keras_prediction - our_model_prediction)) < 0.01:\n",
        "    print('Test PASSED')\n",
        "else:\n",
        "    print('Something went wrong!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvb_dpP4zVLR"
      },
      "source": [
        "### 2. Вычисление производных по входу для слоёв нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcjF2YYxzVLR"
      },
      "source": [
        "В данном задании запрещено использовать численные формулы для вычисления производных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1o1KKmzzVLR"
      },
      "source": [
        "#### 2.1  Реализуйте метод forward для класса CrossEntropy\n",
        "Напоминание: $$ crossentropy = L(p, y) =  - \\sum\\limits_i y_i log p_i, $$\n",
        "где вектор $(p_1, ..., p_k) $ -  выход классификационного алгоритма, а $(y_1,..., y_k)$ - правильные метки класса в унарной кодировке (one-hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "av8WgGAMzVLS"
      },
      "outputs": [],
      "source": [
        "class CrossEntropy(object):\n",
        "    def __init__(self, eps=0.00001):\n",
        "        self.name = 'CrossEntropy'\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, input_data, labels):\n",
        "        out=0\n",
        "        for i,data in enumerate(input_data):\n",
        "            out-=labels[i] @ np.log(data + self.eps).T\n",
        "        return out\n",
        "\n",
        "\n",
        "    def calculate_loss(self,input_data, labels):\n",
        "        return self.forward(input_data, labels)\n",
        "\n",
        "    def grad_x(self, input_data, lables):\n",
        "        # print(input_data.shape,lables.shape)\n",
        "        out=np.empty(input_data.shape[1])\n",
        "        for i,data in enumerate(input_data):\n",
        "            for j,elem in enumerate(data):\n",
        "                # print(elem)\n",
        "                out[j]-=lables[i,j]/(elem+self.eps)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhXJxBudzVLS"
      },
      "source": [
        "#### 2.2  Реализуйте метод grad_x класса CrossEntropy, который возвращает $\\frac{\\partial L}{\\partial p}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaMxh9oHzVLS"
      },
      "source": [
        "Проверить работоспособность кода поможет следующий тест:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Hoar0ZJTzVLS",
        "outputId": "d13e19e3-bda8-4f6d-cf61-16895601f30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n",
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "def numerical_diff_net(net, x, labels):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(len(x[0])):\n",
        "        delta = np.zeros(len(x[0]))\n",
        "        delta[i] = eps\n",
        "        diff = (net.calculate_loss(x + delta, labels) - net.calculate_loss(x-delta, labels)) / (2*eps)\n",
        "        right_answer.append(diff)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_net(net):\n",
        "    x = np.array([[1, 2, 3], [2, 3, 4]])\n",
        "    labels = np.array([[0.3, 0.2, 0.5], [0.3, 0.2, 0.5]])\n",
        "    num_grad = numerical_diff_net(net, x, labels)\n",
        "    grad = net.grad_x(x, labels)\n",
        "    print(grad.shape)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "loss = CrossEntropy()\n",
        "test_net(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jsb7SpizVLS"
      },
      "source": [
        "#### 2.3  Реализуйте метод grad_x класса Softmax, который возвращает $\\frac{\\partial Softmax}{\\partial x}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8k_VGiEzVLS"
      },
      "source": [
        "Проверить работоспособность кода поможет следующий тест:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7EajIZO2zVLS",
        "outputId": "97bf9d9f-549f-466a-ec29-df38e16c7f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 3)\n",
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "def numerical_diff_layer(layer, x):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(len(x[0])):\n",
        "        delta = np.zeros(len(x[0]))\n",
        "        delta[i] = eps\n",
        "        diff = (layer.forward(x + delta) - layer.forward(x-delta)) / (2*eps)\n",
        "        right_answer.append(diff.T)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_layer(layer):\n",
        "    x = np.array([[1, 2, 3], [2, -3, 4]])\n",
        "    num_grad = numerical_diff_layer(layer, x)\n",
        "    print(num_grad.shape)\n",
        "    grad = layer.grad_x(x)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "\n",
        "layer = Softmax()\n",
        "test_layer(layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoT2HTEYzVLT"
      },
      "source": [
        "#### 2.4  Реализуйте метод grad_x для классов ReLU и DenseLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pI-oa3QNzVLT",
        "outputId": "15b997fd-da12-466f-978c-7441a69e95b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 3)\n",
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "layer = ReLU()\n",
        "test_layer(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_gLwCaJmzVLT",
        "outputId": "3e43ef12-a3cb-4d4f-fb97-e301af05b529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 4, 3)\n",
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "layer = DenseLayer(3,4)\n",
        "test_layer(layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfMA32twzVLT"
      },
      "source": [
        "#### 2.5 (4 балла) Для класса Network реализуйте метод grad_x, который должен реализовывать взятие производной от лосса по входу"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network([ReLU(), Softmax()], loss=CrossEntropy())\n",
        "test_net(net)"
      ],
      "metadata": {
        "id": "yZvCw6ieY3CI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a908dca-d298-4d18-97ff-72b62823aecb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n",
            "Test PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ryumlz_AzVLT",
        "outputId": "39206162-adc8-4878-d158-2754ce407e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n",
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "net = Network([DenseLayer(3,784),ReLU(),DenseLayer(784,784),ReLU(),DenseLayer(784,256),ReLU(),DenseLayer(256,3), Softmax()], loss=CrossEntropy())\n",
        "test_net(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHOb3_IKzVLT"
      },
      "source": [
        "### 3. Реализация градиентов по параметрам и метода обратного распространения ошибки с обновлением парметров сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQJ-nrXozVLU"
      },
      "source": [
        "#### 3.1  Реализуйте функции grad_b и grad_W. При подготовке теста grad_W предполагается, что W является отномерным вектором."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "20jwA-LMzVLU",
        "outputId": "80ff2593-b598-4c06-b9a1-579d3fb5fddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "def numerical_grad_b(input_size, output_size, b, W, x):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(len(b)):\n",
        "        delta = np.zeros(b.shape)\n",
        "        delta[i] = eps\n",
        "        dense1 = DenseLayer(input_size, output_size, W_init=W, b_init=b+delta)\n",
        "        dense2 = DenseLayer(input_size, output_size, W_init=W, b_init=b-delta)\n",
        "        diff = (dense1.forward(x) - dense2.forward(x)) / (2*eps)\n",
        "        right_answer.append(diff.T)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_grad_b():\n",
        "    input_size = 3\n",
        "    output_size = 4\n",
        "    W_init = np.random.random((input_size, output_size))\n",
        "    b_init = np.random.random((output_size,))\n",
        "    x = np.random.random((2, input_size))\n",
        "\n",
        "    dense = DenseLayer(input_size, output_size, W_init, b_init)\n",
        "    grad = dense.grad_b(x)\n",
        "\n",
        "    num_grad = numerical_grad_b(input_size, output_size, b_init, W_init, x)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "\n",
        "test_grad_b()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "w9eW3BrAzVLU",
        "outputId": "a4f5e43b-31df-4287-8c2f-cdec99311899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "def numerical_grad_W(input_size, output_size, b, W, x):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(W.shape[0]):\n",
        "        for j in range(W.shape[1]):\n",
        "            delta = np.zeros(W.shape)\n",
        "            delta[i, j] = eps\n",
        "            dense1 = DenseLayer(input_size, output_size, W_init=W+delta, b_init=b)\n",
        "            dense2 = DenseLayer(input_size, output_size, W_init=W-delta, b_init=b)\n",
        "            diff = (dense1.forward(x) - dense2.forward(x)) / (2*eps)\n",
        "            right_answer.append(diff.T)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_grad_W():\n",
        "    input_size = 3\n",
        "    output_size = 4\n",
        "    W_init = np.random.random((input_size, output_size))\n",
        "    b_init = np.random.random((4,))\n",
        "    x = np.random.random((2, input_size))\n",
        "\n",
        "    dense = DenseLayer(input_size, output_size, W_init, b_init)\n",
        "    grad = dense.grad_W(x)\n",
        "\n",
        "    num_grad = numerical_grad_W(input_size, output_size, b_init, W_init, x)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "\n",
        "test_grad_W()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phGknNsHzVLU"
      },
      "source": [
        "#### 3.2 Полностью реализуйте метод обратного распространения ошибки в функции train_step класса Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wWju5WFzVLV"
      },
      "source": [
        "Рекомендуем реализовать сначала функцию Network.grad_param(), которая возвращает список длиной в количество слоёв и элементом которого является список градиентов по параметрам.\n",
        "После чего, имея список градиентов, написать функцию обновления параметров для каждого слоя.\n",
        "\n",
        "Совет: рекомендуем написать тест для кода подсчета градиента по параметрам, чтобы быть уверенным в том, что градиент через всю сеть считается правильно\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeZQY7pgzVLV"
      },
      "source": [
        "#### 3.3 Ознакомьтесь с реализацией функции fit класса Network. Запустите обучение модели. Если всё работает правильно, то точность на валидации должна будет возрастать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "D2vcdfd3zVLV",
        "outputId": "dd2ba1af-5655-4eb8-985b-65bc6f082592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22500/22500 [00:31<00:00, 721.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 epoch: val 0.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22500/22500 [00:27<00:00, 831.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 epoch: val 0.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22500/22500 [00:27<00:00, 824.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 epoch: val 0.92\n"
          ]
        }
      ],
      "source": [
        "net = Network([DenseLayer(784, 10), Softmax()], loss=CrossEntropy())\n",
        "# net = Network([dense1], loss=CrossEntropy())\n",
        "trainX = X_train.reshape(len(X_train), -1)\n",
        "net.fit(trainX, Y_train, validation_split=0.25,\n",
        "            batch_size=2, nb_epoch=3, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "testX = X_test.reshape(len(X_test), -1)\n",
        "pred=net.predict(testX)\n",
        "pred=np.argmax(pred, axis=1)\n",
        "Y_test=np.argmax(Y_test, axis=1)\n",
        "# print(*pred)\n",
        "print(accuracy_score(pred,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKh7XS2lX5Ua",
        "outputId": "a35c2f42-72fe-40ba-e9e3-2bafb265f9ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isn4zTF6zVLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8433b6bd-bc89-471f-cef6-f58971a8b27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 900/900 [07:36<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 epoch: val 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 900/900 [07:19<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 epoch: val 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 206/900 [01:38<06:55,  1.67it/s]"
          ]
        }
      ],
      "source": [
        "net = Network([DenseLayer(784, 64),ReLU(), DenseLayer(64, 10), Softmax()], loss=CrossEntropy())\n",
        "trainX = X_train.reshape(len(X_train), -1)\n",
        "# net.forward(trainX)\n",
        "net.fit(trainX[::10], Y_train[::10], validation_split=0.25,\n",
        "            batch_size=5, nb_epoch=10, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIMicSA2zVLV"
      },
      "source": [
        "#### 3.5 Продемонстрируйте, что ваша реализация позволяет обучать более глубокие нейронные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаю на малом количестве данных, так как обучение требует много времени"
      ],
      "metadata": {
        "id": "DddiCJ5_jNyO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Xu62BCYtzVLV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0d9d7963-48d3-450a-d284-8f7de7786c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 937/937 [06:39<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 epoch: val 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 98/937 [00:30<04:16,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-29efe2e75fdb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# net.forward(trainX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m net.fit(trainX[::6], Y_train[::6], validation_split=0.25,\n\u001b[0m\u001b[1;32m      5\u001b[0m             batch_size=8, nb_epoch=20, learning_rate=0.05)\n",
            "\u001b[0;32m<ipython-input-2-d1479412e5b5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainX, trainY, validation_split, batch_size, nb_epoch, learning_rate)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;31m#validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-d1479412e5b5>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, input_data, labels, learning_rate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mgrad_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-d1479412e5b5>\u001b[0m in \u001b[0;36mgrad_param\u001b[0;34m(self, input_data, labels)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mw_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                     \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mgrad_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# out=out @ layer.W.T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0d66e6ab7e21>\u001b[0m in \u001b[0;36mgrad_W\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mmy_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_vektor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mmy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "net = Network([DenseLayer(784, 32), ReLU(),DenseLayer(32, 16), ReLU(), DenseLayer(16, 10), Softmax()], loss=CrossEntropy())\n",
        "trainX = X_train.reshape(len(X_train), -1)\n",
        "# net.forward(trainX)\n",
        "net.fit(trainX[::6], Y_train[::6], validation_split=0.25,\n",
        "            batch_size=8, nb_epoch=20, learning_rate=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=net.predict(testX)\n",
        "pred=np.argmax(pred, axis=1)\n",
        "\n",
        "# print(*pred)\n",
        "print(accuracy_score(pred,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWN6IiJKVn8O",
        "outputId": "1417290c-8027-45b8-a8f7-493d128b80ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1925\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}